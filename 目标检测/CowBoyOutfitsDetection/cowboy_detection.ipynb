{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pycocotools.coco import COCO\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import random\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 设备配置\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"使用设备: {device}\")\n",
    "\n",
    "def get_category_mapping(coco_json_path):\n",
    "    \"\"\"\n",
    "    从COCO格式的JSON文件中获取category_id到类别名的映射\n",
    "    \"\"\"\n",
    "    coco = COCO(coco_json_path)\n",
    "    \n",
    "    # 尝试从categories获取，如果没有则从annotations中提取唯一的category_id\n",
    "    categories = coco.loadCats(coco.getCatIds())\n",
    "    category_mapping = {cat['id']: cat['name'] for cat in categories}\n",
    "    \n",
    "    return category_mapping\n",
    "\n",
    "def get_num_classes_from_coco(json_file):\n",
    "    \"\"\"从COCO格式的JSON文件中提取类别数量和ID映射\"\"\"\n",
    "    with open(json_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # 收集所有类别ID\n",
    "    all_category_ids = set()\n",
    "    for ann in data.get('annotations', []):\n",
    "        all_category_ids.add(ann['category_id'])\n",
    "    \n",
    "    # 创建从原始ID到连续ID的映射（0为背景，1开始为实际类别）\n",
    "    sorted_ids = sorted(list(all_category_ids))\n",
    "    id_mapping = {original_id: new_id + 1 for new_id, original_id in enumerate(sorted_ids)}\n",
    "    \n",
    "    print(f\"检测到的原始类别IDs: {sorted_ids}\")\n",
    "    print(f\"类别数量: {len(sorted_ids)}\")\n",
    "    print(f\"ID映射: {id_mapping}\")\n",
    "    \n",
    "    return len(sorted_ids), id_mapping\n",
    "\n",
    "class FasterRCNNDataset(Dataset):\n",
    "    def __init__(self, json_file, img_dir, transforms=None, device='cpu'):\n",
    "        with open(json_file, 'r') as f:\n",
    "            self.data = json.load(f)\n",
    "        \n",
    "        self.img_dir = img_dir\n",
    "        self.transforms = transforms\n",
    "        \n",
    "        # 获取类别数量和ID映射\n",
    "        self.num_classes, self.id_mapping = get_num_classes_from_coco(json_file)\n",
    "        \n",
    "        # 创建图像ID到图像信息的映射\n",
    "        self.image_info = {img['id']: img for img in self.data['images']}\n",
    "        \n",
    "        # 创建图像ID到annotations的映射\n",
    "        self.image_annotations = {}\n",
    "        for ann in self.data.get('annotations', []):\n",
    "            image_id = ann['image_id']\n",
    "            if image_id not in self.image_annotations:\n",
    "                self.image_annotations[image_id] = []\n",
    "            self.image_annotations[image_id].append(ann)\n",
    "        \n",
    "        # 只保留有annotations的图像\n",
    "        self.image_ids = list(self.image_annotations.keys())\n",
    "        \n",
    "        print(f\"数据集包含 {len(self.image_ids)} 张有标注的图像\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_id = self.image_ids[idx]\n",
    "        img_info = self.image_info[image_id]\n",
    "        img_path = os.path.join(self.img_dir, img_info['file_name'])\n",
    "        \n",
    "        # 加载图像\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        # 获取该图像的所有annotations\n",
    "        annotations = self.image_annotations[image_id]\n",
    "        \n",
    "        boxes = []\n",
    "        labels = []\n",
    "        \n",
    "        for ann in annotations:\n",
    "            # 获取边界框坐标 [x, y, width, height] -> [x1, y1, x2, y2]\n",
    "            bbox = ann['bbox']\n",
    "            x1, y1, w, h = bbox\n",
    "            x2 = x1 + w\n",
    "            y2 = y1 + h\n",
    "            \n",
    "            # 确保边界框在图像范围内\n",
    "            x1 = max(0, x1)\n",
    "            y1 = max(0, y1)\n",
    "            x2 = min(img_info['width'], x2)\n",
    "            y2 = min(img_info['height'], y2)\n",
    "            \n",
    "            # 检查边界框是否有效\n",
    "            if x2 > x1 and y2 > y1:\n",
    "                boxes.append([x1, y1, x2, y2])\n",
    "                # 映射category_id到连续的标签\n",
    "                category_id = ann['category_id']\n",
    "                if category_id in self.id_mapping:\n",
    "                    labels.append(self.id_mapping[category_id])\n",
    "                else:\n",
    "                    labels.append(1)  # 默认标签\n",
    "        \n",
    "        # 如果没有有效的边界框，创建一个虚拟的背景框\n",
    "        if len(boxes) == 0:\n",
    "            boxes.append([0, 0, img_info['width'], img_info['height']])\n",
    "            labels.append(0)  # 背景类\n",
    "        \n",
    "        # 转换为张量\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
    "        \n",
    "        target = {\n",
    "            'boxes': boxes,\n",
    "            'labels': labels,\n",
    "            'image_id': str(image_id)\n",
    "        }\n",
    "        \n",
    "        if self.transforms:\n",
    "            image = self.transforms(image)\n",
    "        \n",
    "        return image, target\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    \"\"\"\n",
    "    测试数据集（用于预测）\n",
    "    \"\"\"\n",
    "    def __init__(self, csv_file, img_dir, transform=None, device='cpu'):\n",
    "        self.df = pd.read_csv(csv_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.device = device\n",
    "        \n",
    "        print(f\"测试数据集初始化完成，共{len(self.df)}张图像\")\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # 获取图像信息\n",
    "        row = self.df.iloc[idx]\n",
    "        image_id = row['id']\n",
    "        image_path = row['file_name']\n",
    "        # 加载图像\n",
    "        img_path = os.path.join(self.img_dir, image_path)\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        # 应用变换\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, image_id\n",
    "\n",
    "def create_faster_rcnn_model(num_classes):\n",
    "    \"\"\"\n",
    "    创建Faster R-CNN模型\n",
    "    \"\"\"\n",
    "    # 加载预训练的Faster R-CNN模型\n",
    "    model = fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "    \n",
    "    # 替换分类器头部\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes + 1)  # +1 for background\n",
    "    \n",
    "    return model\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    自定义collate函数，用于处理不同大小的图像和目标\n",
    "    \"\"\"\n",
    "    images, targets = zip(*batch)\n",
    "    return list(images), list(targets)\n",
    "\n",
    "def test_collate_fn(batch):\n",
    "    \"\"\"\n",
    "    测试数据的collate函数\n",
    "    \"\"\"\n",
    "    images, image_ids = zip(*batch)\n",
    "    return list(images), list(image_ids)\n",
    "\n",
    "def train_model(model, train_loader, val_loader, num_epochs=10, lr=0.001):\n",
    "    \"\"\"\n",
    "    训练Faster R-CNN模型\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    \n",
    "    # 优化器\n",
    "    params = [p for p in model.parameters() if p.requires_grad]\n",
    "    optimizer = optim.SGD(params, lr=lr, momentum=0.9, weight_decay=0.0005)\n",
    "    \n",
    "    # 学习率调度器\n",
    "    lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "    \n",
    "    best_loss = float('inf')\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        # 训练阶段\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_batches = 0\n",
    "        \n",
    "        train_pbar = tqdm(train_loader, desc=f\"Training Epoch {epoch+1}\")\n",
    "        for images, targets in train_pbar:\n",
    "            # 移动数据到设备\n",
    "            images = [img.to(device) for img in images]\n",
    "            targets = [{k: v.to(device) if hasattr(v, 'to') else v for k, v in t.items()} for t in targets]\n",
    "            \n",
    "            # 前向传播\n",
    "            loss_dict = model(images, targets)\n",
    "            losses = sum(loss for loss in loss_dict.values())\n",
    "            \n",
    "            # 反向传播\n",
    "            optimizer.zero_grad()\n",
    "            losses.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += losses.item()\n",
    "            train_batches += 1\n",
    "            \n",
    "            # 更新进度条\n",
    "            train_pbar.set_postfix({\n",
    "                'Loss': f'{losses.item():.4f}',\n",
    "                'Avg Loss': f'{train_loss/train_batches:.4f}'\n",
    "            })\n",
    "        \n",
    "        avg_train_loss = train_loss / train_batches\n",
    "        \n",
    "        # 验证阶段\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_batches = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            val_pbar = tqdm(val_loader, desc=f\"Validation Epoch {epoch+1}\")\n",
    "            for images, targets in val_pbar:\n",
    "                # 移动数据到设备\n",
    "                images = [img.to(device) for img in images]\n",
    "                targets = [{k: v.to(device) if hasattr(v, 'to') else v for k, v in t.items()} for t in targets]\n",
    "                \n",
    "                # 前向传播\n",
    "                model.train()\n",
    "                loss_dict = model(images, targets)\n",
    "                losses = sum(loss for loss in loss_dict.values())\n",
    "                model.eval()\n",
    "                val_loss += losses.item()\n",
    "                val_batches += 1\n",
    "                \n",
    "                # 更新进度条\n",
    "                val_pbar.set_postfix({\n",
    "                    'Loss': f'{losses.item():.4f}',\n",
    "                    'Avg Loss': f'{val_loss/val_batches:.4f}'\n",
    "                })\n",
    "        \n",
    "        avg_val_loss = val_loss / val_batches\n",
    "        \n",
    "        print(f\"Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}\")\n",
    "        \n",
    "        # 保存最佳模型\n",
    "        if avg_val_loss < best_loss:\n",
    "            best_loss = avg_val_loss\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': best_loss,\n",
    "                'num_classes': model.roi_heads.box_predictor.cls_score.out_features - 1\n",
    "            }, 'best_faster_rcnn_model.pth')\n",
    "            print(f\"保存最佳模型，验证损失: {best_loss:.4f}\")\n",
    "        \n",
    "        # 更新学习率\n",
    "        lr_scheduler.step()\n",
    "    \n",
    "    print(\"\\n训练完成！\")\n",
    "    return model\n",
    "\n",
    "def predict_and_generate_submission(model, csv_file, img_dir, output_file='submission.csv', \n",
    "                                  device='cpu', conf_threshold=0.01):\n",
    "    \"\"\"\n",
    "    使用训练好的模型进行预测并生成提交文件\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # 创建测试数据集\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    dataset = TestDataset(csv_file, img_dir, transform, device=device)\n",
    "    dataloader = DataLoader(dataset, batch_size=1, shuffle=False, collate_fn=test_collate_fn)\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, image_ids in tqdm(dataloader, desc=\"预测中\"):\n",
    "            # 移动图像到设备\n",
    "            images = [img.to(device) for img in images]\n",
    "            \n",
    "            # 预测\n",
    "            predictions = model(images)\n",
    "            \n",
    "            for i, (pred, image_id) in enumerate(zip(predictions, image_ids)):\n",
    "                boxes = pred['boxes'].cpu().numpy()\n",
    "                scores = pred['scores'].cpu().numpy()\n",
    "                labels = pred['labels'].cpu().numpy()\n",
    "                \n",
    "                # 过滤低置信度的预测\n",
    "                valid_indices = scores >= conf_threshold\n",
    "                boxes = boxes[valid_indices]\n",
    "                scores = scores[valid_indices]\n",
    "                labels = labels[valid_indices]\n",
    "                \n",
    "                # 格式化预测结果\n",
    "                for box, score, label in zip(boxes, scores, labels):\n",
    "                    x1, y1, x2, y2 = box\n",
    "                    width = x2 - x1\n",
    "                    height = y2 - y1\n",
    "                    \n",
    "                    results.append({\n",
    "                        'image_id': image_id,\n",
    "                        'category_id': int(label),\n",
    "                        'bbox': [float(x1), float(y1), float(width), float(height)],\n",
    "                        'score': float(score)\n",
    "                    })\n",
    "    \n",
    "    # 保存结果\n",
    "    df_results = pd.DataFrame(results)\n",
    "    df_results.to_csv(output_file, index=False)\n",
    "    print(f\"预测结果已保存到 {output_file}\")\n",
    "    print(f\"总共生成了 {len(results)} 个预测结果\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "def predict_from_test_csv_to_json(model, csv_file, img_dir, output_file='submission.json', \n",
    "                                  device=torch.device('cuda' if torch.cuda.is_available() else 'cpu'), \n",
    "                                  conf_threshold=0.01):\n",
    "    \"\"\"\n",
    "    从test.csv预测并生成JSON格式提交文件\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # 创建数据集（不使用数据增强）\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    dataset = TestDataset(csv_file, img_dir, transform, device=device)\n",
    "    dataloader = DataLoader(dataset, batch_size=1, shuffle=False, collate_fn=test_collate_fn)\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, image_ids in tqdm(dataloader, desc=\"预测中\"):\n",
    "            # 移动图像到设备\n",
    "            images = [img.to(device) for img in images]\n",
    "            \n",
    "            # 预测\n",
    "            predictions = model(images)\n",
    "            \n",
    "            for i, (pred, image_id) in enumerate(zip(predictions, image_ids)):\n",
    "                boxes = pred['boxes'].cpu().numpy()\n",
    "                scores = pred['scores'].cpu().numpy()\n",
    "                labels = pred['labels'].cpu().numpy()\n",
    "                \n",
    "                # 过滤低置信度的预测\n",
    "                valid_indices = scores >= conf_threshold\n",
    "                boxes = boxes[valid_indices]\n",
    "                scores = scores[valid_indices]\n",
    "                labels = labels[valid_indices]\n",
    "                \n",
    "                # 格式化预测结果\n",
    "                for box, score, label in zip(boxes, scores, labels):\n",
    "                    x1, y1, x2, y2 = box\n",
    "                    width = x2 - x1\n",
    "                    height = y2 - y1\n",
    "                    \n",
    "                    results.append({\n",
    "                        'image_id': image_id,\n",
    "                        'category_id': int(label),\n",
    "                        'bbox': [float(x1), float(y1), float(width), float(height)],\n",
    "                        'score': float(score)\n",
    "                    })\n",
    "    \n",
    "    # 保存为JSON格式\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "    \n",
    "    print(f\"预测结果已保存到 {output_file}\")\n",
    "    print(f\"总共生成了 {len(results)} 个预测结果\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "def visualize_predictions(model, json_file, img_dir, num_images=5, device='cpu', conf_threshold=0.03):\n",
    "    \"\"\"\n",
    "    可视化预测结果\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # 创建数据集\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    dataset = FasterRCNNDataset(json_file, img_dir, transform, device=device)\n",
    "    dataloader = DataLoader(dataset, batch_size=1, shuffle=True, collate_fn=collate_fn)\n",
    "    \n",
    "    # 反归一化函数\n",
    "    def denormalize(tensor):\n",
    "        mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "        std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "        return tensor * std + mean\n",
    "    \n",
    "    count = 0\n",
    "    with torch.no_grad():\n",
    "        for images, targets in dataloader:\n",
    "            if count >= num_images:\n",
    "                break\n",
    "            \n",
    "            # 移动到设备\n",
    "            images = [img.to(device) for img in images]\n",
    "            \n",
    "            # 预测\n",
    "            predictions = model(images)\n",
    "            \n",
    "            # 可视化第一张图像\n",
    "            img = images[0].cpu()\n",
    "            img = denormalize(img)\n",
    "            img = torch.clamp(img, 0, 1)\n",
    "            \n",
    "            target = targets[0]\n",
    "            pred = predictions[0]\n",
    "            \n",
    "            # 创建图像\n",
    "            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 7))\n",
    "            \n",
    "            # 显示原图和真实标注\n",
    "            ax1.imshow(img.permute(1, 2, 0))\n",
    "            ax1.set_title('Ground Truth')\n",
    "            \n",
    "            # 绘制真实边界框\n",
    "            gt_boxes = target['boxes'].cpu().numpy()\n",
    "            gt_labels = target['labels'].cpu().numpy()\n",
    "            \n",
    "            for box, label in zip(gt_boxes, gt_labels):\n",
    "                x1, y1, x2, y2 = box\n",
    "                rect = patches.Rectangle((x1, y1), x2-x1, y2-y1, \n",
    "                                       linewidth=2, edgecolor='red', facecolor='none')\n",
    "                ax1.add_patch(rect)\n",
    "                ax1.text(x1, y1-5, f'GT: {label}', color='red', fontsize=10, weight='bold')\n",
    "            \n",
    "            # 显示预测结果\n",
    "            ax2.imshow(img.permute(1, 2, 0))\n",
    "            ax2.set_title('Predictions')\n",
    "            \n",
    "            # 绘制预测边界框\n",
    "            pred_boxes = pred['boxes'].cpu().numpy()\n",
    "            pred_scores = pred['scores'].cpu().numpy()\n",
    "            pred_labels = pred['labels'].cpu().numpy()\n",
    "            \n",
    "            # 过滤低置信度预测\n",
    "            valid_indices = pred_scores >= conf_threshold\n",
    "            pred_boxes = pred_boxes[valid_indices]\n",
    "            pred_scores = pred_scores[valid_indices]\n",
    "            pred_labels = pred_labels[valid_indices]\n",
    "            \n",
    "            for box, score, label in zip(pred_boxes, pred_scores, pred_labels):\n",
    "                x1, y1, x2, y2 = box\n",
    "                rect = patches.Rectangle((x1, y1), x2-x1, y2-y1, \n",
    "                                       linewidth=2, edgecolor='blue', facecolor='none')\n",
    "                ax2.add_patch(rect)\n",
    "                ax2.text(x1, y1-5, f'Pred: {label} ({score:.2f})', \n",
    "                        color='blue', fontsize=10, weight='bold')\n",
    "            \n",
    "            ax1.axis('off')\n",
    "            ax2.axis('off')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            count += 1\n",
    "\n",
    "def split_train_data(json_file, train_ratio=0.8, random_seed=42):\n",
    "    \"\"\"\n",
    "    从训练数据中分割出训练集和验证集\n",
    "    \"\"\"\n",
    "    with open(json_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # 设置随机种子确保可重复性\n",
    "    random.seed(random_seed)\n",
    "    \n",
    "    # 获取所有图像\n",
    "    images = data['images']\n",
    "    annotations = data['annotations']\n",
    "    \n",
    "    # 按图像ID分组标注\n",
    "    image_to_anns = {}\n",
    "    for ann in annotations:\n",
    "        img_id = ann['image_id']\n",
    "        if img_id not in image_to_anns:\n",
    "            image_to_anns[img_id] = []\n",
    "        image_to_anns[img_id].append(ann)\n",
    "    \n",
    "    # 分割图像\n",
    "    train_images, val_images = train_test_split(\n",
    "        images, train_size=train_ratio, random_state=random_seed\n",
    "    )\n",
    "    \n",
    "    # 获取对应的标注\n",
    "    train_image_ids = {img['id'] for img in train_images}\n",
    "    val_image_ids = {img['id'] for img in val_images}\n",
    "    \n",
    "    train_annotations = []\n",
    "    val_annotations = []\n",
    "    \n",
    "    for ann in annotations:\n",
    "        if ann['image_id'] in train_image_ids:\n",
    "            train_annotations.append(ann)\n",
    "        elif ann['image_id'] in val_image_ids:\n",
    "            val_annotations.append(ann)\n",
    "    \n",
    "    # 创建训练集数据\n",
    "    train_data = {\n",
    "        'info': data['info'],\n",
    "        'licenses': data.get('licenses', []),\n",
    "        'categories': data['categories'],\n",
    "        'images': train_images,\n",
    "        'annotations': train_annotations\n",
    "    }\n",
    "    \n",
    "    # 创建验证集数据\n",
    "    val_data = {\n",
    "        'info': data['info'],\n",
    "        'licenses': data.get('licenses', []),\n",
    "        'categories': data['categories'],\n",
    "        'images': val_images,\n",
    "        'annotations': val_annotations\n",
    "    }\n",
    "    \n",
    "    return train_data, val_data\n",
    "\n",
    "def run_training(train_json='train.json', val_json=None, img_dir='images',\n",
    "                num_epochs=10, batch_size=4, lr=0.001, train_ratio=0.8):\n",
    "    \"\"\"\n",
    "    运行训练流程\n",
    "    \"\"\"\n",
    "    print(\"开始训练流程...\")\n",
    "    \n",
    "    # 如果没有提供验证集，从训练集中分割\n",
    "    if val_json is None or not os.path.exists(val_json):\n",
    "        print(f\"未找到验证集文件，从训练集中分割数据（训练集比例: {train_ratio}）\")\n",
    "        \n",
    "        # 分割数据\n",
    "        train_data, val_data = split_train_data(train_json, train_ratio)\n",
    "        \n",
    "        # 保存临时文件\n",
    "        temp_train_json = 'temp_train.json'\n",
    "        temp_val_json = 'temp_val.json'\n",
    "        \n",
    "        with open(temp_train_json, 'w') as f:\n",
    "            json.dump(train_data, f)\n",
    "        with open(temp_val_json, 'w') as f:\n",
    "            json.dump(val_data, f)\n",
    "        \n",
    "        train_json_file = temp_train_json\n",
    "        val_json_file = temp_val_json\n",
    "        \n",
    "        print(f\"数据分割完成：\")\n",
    "        print(f\"  训练集: {len(train_data['images'])} 张图像, {len(train_data['annotations'])} 个标注\")\n",
    "        print(f\"  验证集: {len(val_data['images'])} 张图像, {len(val_data['annotations'])} 个标注\")\n",
    "    else:\n",
    "        train_json_file = train_json\n",
    "        val_json_file = val_json\n",
    "    \n",
    "    # 数据变换\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    # 创建数据集\n",
    "    train_dataset = FasterRCNNDataset(train_json_file, img_dir, train_transform, device=device)\n",
    "    val_dataset = FasterRCNNDataset(val_json_file, img_dir, val_transform, device=device)\n",
    "    \n",
    "    # 创建数据加载器\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, \n",
    "                             collate_fn=collate_fn, num_workers=2)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, \n",
    "                           collate_fn=collate_fn, num_workers=2)\n",
    "    \n",
    "    # 创建模型\n",
    "    num_classes = train_dataset.num_classes\n",
    "    model = create_faster_rcnn_model(num_classes)\n",
    "    \n",
    "    print(f\"模型创建完成，类别数: {num_classes}\")\n",
    "    \n",
    "    # 训练模型\n",
    "    trained_model = train_model(model, train_loader, val_loader, num_epochs, lr)\n",
    "    \n",
    "    return trained_model\n",
    "\n",
    "def run_prediction(model_path='best_faster_rcnn_model.pth', test_csv='test.csv', \n",
    "                  img_dir='images', output_file='submission.json'):\n",
    "    \"\"\"\n",
    "    运行预测流程\n",
    "    \"\"\"\n",
    "    print(\"开始预测流程...\")\n",
    "    \n",
    "    # 加载模型\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    num_classes = checkpoint['num_classes']\n",
    "    \n",
    "    model = create_faster_rcnn_model(num_classes)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.to(device)\n",
    "    \n",
    "    print(f\"模型加载完成，类别数: {num_classes}\")\n",
    "    \n",
    "    # 进行预测\n",
    "    results = predict_from_test_csv_to_json(\n",
    "        model=model,\n",
    "        csv_file=test_csv,\n",
    "        img_dir=img_dir,\n",
    "        output_file=output_file,\n",
    "        device=device,\n",
    "        conf_threshold=0.01\n",
    "    )\n",
    "    \n",
    "    return results\n",
    "\n",
    "def run_visualization(model_path='best_faster_rcnn_model.pth', json_file='train.json', \n",
    "                     img_dir='images', conf_threshold=0.9):\n",
    "    \"\"\"\n",
    "    运行可视化\n",
    "    \"\"\"\n",
    "    print(\"开始可视化...\")\n",
    "    \n",
    "    # 加载模型\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    num_classes = checkpoint['num_classes']\n",
    "    \n",
    "    model = create_faster_rcnn_model(num_classes)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.to(device)\n",
    "    \n",
    "    # 可视化\n",
    "    visualize_predictions(\n",
    "        model=model,\n",
    "        json_file=json_file,\n",
    "        img_dir=img_dir,\n",
    "        num_images=5,\n",
    "        device=device,\n",
    "        conf_threshold=conf_threshold\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练模型\n",
    "trained_model = run_training(\n",
    "    train_json='train.json',\n",
    "    val_json='val.json', \n",
    "    img_dir='images',\n",
    "    num_epochs=1,\n",
    "    batch_size=1,\n",
    "    lr=0.001\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 进行预测\n",
    "results = run_prediction(\n",
    "    model_path='best_faster_rcnn_model.pth',\n",
    "    test_csv='test.csv',\n",
    "    img_dir='images',\n",
    "    output_file='submission.json'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def visualize_test_predictions(model_path='best_faster_rcnn_model.pth', test_csv='test.csv', jsonfile='train.json',\n",
    "                              img_dir='images', num_images=5, device='cpu', conf_threshold=0.3, nms_threshold=0.5):\n",
    "    \"\"\"\n",
    "    可视化test.csv中图片的预测结果\n",
    "    \n",
    "    Args:\n",
    "        model_path: 模型文件路径\n",
    "        test_csv: 测试CSV文件路径\n",
    "        img_dir: 图片目录\n",
    "        num_images: 要显示的图片数量\n",
    "        device: 设备\n",
    "        conf_threshold: 置信度阈值\n",
    "        nms_threshold: NMS阈值\n",
    "    \"\"\"\n",
    "    import torchvision.ops as ops\n",
    "    \n",
    "    print(f\"开始可视化test.csv中的预测结果...\")\n",
    "    id2name = get_category_mapping(jsonfile)\n",
    "    print(id2name)\n",
    "    # 加载模型\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    num_classes = checkpoint['num_classes']\n",
    "    \n",
    "    model = create_faster_rcnn_model(num_classes)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    print(f\"模型加载完成，类别数: {num_classes}\")\n",
    "    \n",
    "    # 创建测试数据集\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    dataset = TestDataset(test_csv, img_dir, transform, device=device)\n",
    "    dataloader = DataLoader(dataset, batch_size=1, shuffle=True, collate_fn=test_collate_fn)\n",
    "    \n",
    "    # 反归一化函数\n",
    "    def denormalize(tensor):\n",
    "        mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "        std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "        return tensor * std + mean\n",
    "    \n",
    "    count = 0\n",
    "    with torch.no_grad():\n",
    "        for images, image_ids in dataloader:\n",
    "            if count >= num_images:\n",
    "                break\n",
    "            \n",
    "            # 移动到设备\n",
    "            images = [img.to(device) for img in images]\n",
    "            \n",
    "            # 预测\n",
    "            predictions = model(images)\n",
    "            \n",
    "            # 可视化第一张图像\n",
    "            img = images[0].cpu()\n",
    "            img = denormalize(img)\n",
    "            img = torch.clamp(img, 0, 1)\n",
    "            \n",
    "            pred = predictions[0]\n",
    "            image_id = image_ids[0]\n",
    "            \n",
    "            # 获取预测结果\n",
    "            pred_boxes = pred['boxes'].cpu().numpy()\n",
    "            pred_scores = pred['scores'].cpu().numpy()\n",
    "            pred_labels = pred['labels'].cpu().numpy()\n",
    "            \n",
    "            # 过滤低置信度预测\n",
    "            valid_indices = pred_scores >= conf_threshold\n",
    "            pred_boxes = pred_boxes[valid_indices]\n",
    "            pred_scores = pred_scores[valid_indices]\n",
    "            pred_labels = pred_labels[valid_indices]\n",
    "            \n",
    "            # 应用NMS\n",
    "            if len(pred_boxes) > 0:\n",
    "                # 转换为torch tensor进行NMS\n",
    "                boxes_tensor = torch.tensor(pred_boxes, dtype=torch.float32)\n",
    "                scores_tensor = torch.tensor(pred_scores, dtype=torch.float32)\n",
    "                \n",
    "                # 应用NMS\n",
    "                keep_indices = ops.nms(boxes_tensor, scores_tensor, nms_threshold)\n",
    "                \n",
    "                # 保留NMS后的结果\n",
    "                pred_boxes = pred_boxes[keep_indices.numpy()]\n",
    "                pred_scores = pred_scores[keep_indices.numpy()]\n",
    "                pred_labels = pred_labels[keep_indices.numpy()]\n",
    "            \n",
    "            # 创建图像\n",
    "            fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n",
    "            \n",
    "            # 显示图像\n",
    "            ax.imshow(img.permute(1, 2, 0))\n",
    "            ax.set_title(f'Test Image: {image_id} (Found {len(pred_boxes)} objects)', fontsize=14, fontweight='bold')\n",
    "            \n",
    "            # 绘制预测边界框\n",
    "            colors = ['red', 'blue', 'green', 'yellow', 'purple', 'orange', 'pink', 'brown']\n",
    "            \n",
    "            for i, (box, score, label) in enumerate(zip(pred_boxes, pred_scores, pred_labels)):\n",
    "                x1, y1, x2, y2 = box\n",
    "                color = colors[i % len(colors)]\n",
    "                \n",
    "                id2id = {87: 1, 131: 2, 318: 3, 588: 4, 1034: 5}\n",
    "                \n",
    "                reversed_dict = {v: id2name[k] for k, v in id2id.items()}\n",
    "                # 绘制边界框\n",
    "                rect = patches.Rectangle((x1, y1), x2-x1, y2-y1, \n",
    "                                       linewidth=3, edgecolor=color, facecolor='none')\n",
    "                ax.add_patch(rect)\n",
    "                \n",
    "                # 添加标签和置信度\n",
    "                ax.text(x1, y1-10, f'Class {reversed_dict[label]}: {score:.3f}', \n",
    "                       color=color, fontsize=12, weight='bold',\n",
    "                       bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8))\n",
    "            \n",
    "            # 如果没有检测到对象\n",
    "            if len(pred_boxes) == 0:\n",
    "                ax.text(0.5, 0.5, 'No objects detected\\n(try lowering conf_threshold)', \n",
    "                       transform=ax.transAxes, ha='center', va='center',\n",
    "                       fontsize=16, color='red', weight='bold',\n",
    "                       bbox=dict(boxstyle='round,pad=0.5', facecolor='yellow', alpha=0.8))\n",
    "            \n",
    "            ax.axis('off')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            # 打印详细信息\n",
    "            print(f\"\\n图像 {image_id} 的预测结果:\")\n",
    "            print(f\"  - 检测到 {len(pred_boxes)} 个对象\")\n",
    "            print(f\"  - 置信度阈值: {conf_threshold}\")\n",
    "            print(f\"  - NMS阈值: {nms_threshold}\")\n",
    "            if len(pred_boxes) > 0:\n",
    "                for i, (box, score, label) in enumerate(zip(pred_boxes, pred_scores, pred_labels)):\n",
    "                    print(f\"  - 对象 {i+1}: 类别 {label}, 置信度 {score:.3f}, 边界框 [{box[0]:.1f}, {box[1]:.1f}, {box[2]:.1f}, {box[3]:.1f}]\")\n",
    "            print(\"-\" * 50)\n",
    "            \n",
    "            count += 1\n",
    "    \n",
    "    print(f\"\\n可视化完成！共显示了 {count} 张图像的预测结果。\")\n",
    "\n",
    "# 调用函数的示例\n",
    "def run_test_visualization():\n",
    "    \"\"\"\n",
    "    运行test.csv图片的可视化\n",
    "    \"\"\"\n",
    "    visualize_test_predictions(\n",
    "        model_path='best_faster_rcnn_model.pth',\n",
    "        test_csv='test.csv',\n",
    "        img_dir='images',\n",
    "        num_images=5,  # 显示5张图片\n",
    "        device=device,\n",
    "        conf_threshold=0.75,  # 置信度阈值，可以调整\n",
    "        nms_threshold=0.7    # NMS阈值，解决重叠框问题\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "def visualize_test_predictions(model_path='best_faster_rcnn_model.pth', test_csv='test.csv', jsonfile='train.json',\n",
    "                              img_dir='images', num_images=5, device='cpu', conf_threshold=0.3, nms_threshold=0.5):\n",
    "    \"\"\"\n",
    "    可视化test.csv中图片的预测结果\n",
    "    \n",
    "    Args:\n",
    "        model_path: 模型文件路径\n",
    "        test_csv: 测试CSV文件路径\n",
    "        img_dir: 图片目录\n",
    "        num_images: 要显示的图片数量\n",
    "        device: 设备\n",
    "        conf_threshold: 置信度阈值\n",
    "        nms_threshold: NMS阈值\n",
    "    \"\"\"\n",
    "    import torchvision.ops as ops\n",
    "    \n",
    "    print(f\"开始可视化test.csv中的预测结果...\")\n",
    "    id2name = get_category_mapping(jsonfile)\n",
    "    print(id2name)\n",
    "    # 加载模型\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    num_classes = checkpoint['num_classes']\n",
    "    \n",
    "    model = create_faster_rcnn_model(num_classes)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    print(f\"模型加载完成，类别数: {num_classes}\")\n",
    "    \n",
    "    # 创建测试数据集\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    dataset = TestDataset(test_csv, img_dir, transform, device=device)\n",
    "    dataloader = DataLoader(dataset, batch_size=1, shuffle=True, collate_fn=test_collate_fn)\n",
    "    \n",
    "    # 反归一化函数\n",
    "    def denormalize(tensor):\n",
    "        mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "        std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "        return tensor * std + mean\n",
    "    \n",
    "    count = 0\n",
    "    with torch.no_grad():\n",
    "        for images, image_ids in dataloader:\n",
    "            if count >= num_images:\n",
    "                break\n",
    "            \n",
    "            # 移动到设备\n",
    "            images = [img.to(device) for img in images]\n",
    "            \n",
    "            # 预测\n",
    "            predictions = model(images)\n",
    "            \n",
    "            # 可视化第一张图像\n",
    "            img = images[0].cpu()\n",
    "            img = denormalize(img)\n",
    "            img = torch.clamp(img, 0, 1)\n",
    "            \n",
    "            pred = predictions[0]\n",
    "            image_id = image_ids[0]\n",
    "            \n",
    "            # 获取预测结果\n",
    "            pred_boxes = pred['boxes'].cpu().numpy()\n",
    "            pred_scores = pred['scores'].cpu().numpy()\n",
    "            pred_labels = pred['labels'].cpu().numpy()\n",
    "            \n",
    "            # 过滤低置信度预测\n",
    "            valid_indices = pred_scores >= conf_threshold\n",
    "            pred_boxes = pred_boxes[valid_indices]\n",
    "            pred_scores = pred_scores[valid_indices]\n",
    "            pred_labels = pred_labels[valid_indices]\n",
    "            \n",
    "            # 应用NMS\n",
    "            if len(pred_boxes) > 0:\n",
    "                # 转换为torch tensor进行NMS\n",
    "                boxes_tensor = torch.tensor(pred_boxes, dtype=torch.float32)\n",
    "                scores_tensor = torch.tensor(pred_scores, dtype=torch.float32)\n",
    "                \n",
    "                # 应用NMS\n",
    "                keep_indices = ops.nms(boxes_tensor, scores_tensor, nms_threshold)\n",
    "                \n",
    "                # 保留NMS后的结果\n",
    "                pred_boxes = pred_boxes[keep_indices.numpy()]\n",
    "                pred_scores = pred_scores[keep_indices.numpy()]\n",
    "                pred_labels = pred_labels[keep_indices.numpy()]\n",
    "            \n",
    "            # 创建图像\n",
    "            fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n",
    "            \n",
    "            # 显示图像\n",
    "            ax.imshow(img.permute(1, 2, 0))\n",
    "            ax.set_title(f'Test Image: {image_id} (Found {len(pred_boxes)} objects)', fontsize=14, fontweight='bold')\n",
    "            \n",
    "            # 绘制预测边界框\n",
    "            colors = ['red', 'blue', 'green', 'yellow', 'purple', 'orange', 'pink', 'brown']\n",
    "            \n",
    "            for i, (box, score, label) in enumerate(zip(pred_boxes, pred_scores, pred_labels)):\n",
    "                x1, y1, x2, y2 = box\n",
    "                color = colors[i % len(colors)]\n",
    "                \n",
    "                id2id = {87: 1, 131: 2, 318: 3, 588: 4, 1034: 5}\n",
    "                \n",
    "                reversed_dict = {v: id2name[k] for k, v in id2id.items()}\n",
    "                # 绘制边界框\n",
    "                rect = patches.Rectangle((x1, y1), x2-x1, y2-y1, \n",
    "                                       linewidth=3, edgecolor=color, facecolor='none')\n",
    "                ax.add_patch(rect)\n",
    "                \n",
    "                # 添加标签和置信度\n",
    "                ax.text(x1, y1-10, f'Class {reversed_dict[label]}: {score:.3f}', \n",
    "                       color=color, fontsize=12, weight='bold',\n",
    "                       bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8))\n",
    "            \n",
    "            # 如果没有检测到对象\n",
    "            if len(pred_boxes) == 0:\n",
    "                ax.text(0.5, 0.5, 'No objects detected\\n(try lowering conf_threshold)', \n",
    "                       transform=ax.transAxes, ha='center', va='center',\n",
    "                       fontsize=16, color='red', weight='bold',\n",
    "                       bbox=dict(boxstyle='round,pad=0.5', facecolor='yellow', alpha=0.8))\n",
    "            \n",
    "            ax.axis('off')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            # 打印详细信息\n",
    "            print(f\"\\n图像 {image_id} 的预测结果:\")\n",
    "            print(f\"  - 检测到 {len(pred_boxes)} 个对象\")\n",
    "            print(f\"  - 置信度阈值: {conf_threshold}\")\n",
    "            print(f\"  - NMS阈值: {nms_threshold}\")\n",
    "            if len(pred_boxes) > 0:\n",
    "                for i, (box, score, label) in enumerate(zip(pred_boxes, pred_scores, pred_labels)):\n",
    "                    print(f\"  - 对象 {i+1}: 类别 {label}, 置信度 {score:.3f}, 边界框 [{box[0]:.1f}, {box[1]:.1f}, {box[2]:.1f}, {box[3]:.1f}]\")\n",
    "            print(\"-\" * 50)\n",
    "            \n",
    "            count += 1\n",
    "    \n",
    "    print(f\"\\n可视化完成！共显示了 {count} 张图像的预测结果。\")\n",
    "\n",
    "# 调用函数的示例\n",
    "def run_test_visualization():\n",
    "    \"\"\"\n",
    "    运行test.csv图片的可视化\n",
    "    \"\"\"\n",
    "    visualize_test_predictions(\n",
    "        model_path='best_faster_rcnn_model.pth',\n",
    "        test_csv='test.csv',\n",
    "        img_dir='images',\n",
    "        num_images=5,  # 显示5张图片\n",
    "        device=device,\n",
    "        conf_threshold=0.75,  # 置信度阈值，可以调整\n",
    "        nms_threshold=0.7    # NMS阈值，解决重叠框问题\n",
    "    )\n",
    "\n",
    "\n",
    "# 可视化test.csv中的图片预测效果\n",
    "run_test_visualization()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
